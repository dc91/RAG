{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdf28336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "import pymupdf4llm\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import fitz\n",
    "\n",
    "MD_DIRECTORY = \"../../md_data\"\n",
    "PDF_DIRECTORY = \"../../temp_pdf\"\n",
    "out_base = MD_DIRECTORY\n",
    "img_base = MD_DIRECTORY + \"/images\"\n",
    "md_base = MD_DIRECTORY + \"/md\"\n",
    "txt_base = MD_DIRECTORY + \"/txt\"\n",
    "os.makedirs(out_base, exist_ok=True)\n",
    "os.makedirs(img_base, exist_ok=True)\n",
    "os.makedirs(md_base, exist_ok=True)\n",
    "os.makedirs(txt_base, exist_ok=True)\n",
    "MAX_CHUNK = 640\n",
    "MIN_CHUNK = 512\n",
    "CONTROL_SPACE_REGEX = re.compile(\n",
    "    r'[\\x00-\\x1F\\x7F\\u00A0\\u1680\\u180E\\u2000-\\u200F\\u2028\\u2029\\u202F\\u205F\\u2060\\u2061\\u2062\\u2063\\u2064\\uFEFF]'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaf118b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for filename in os.listdir(PDF_DIRECTORY):\n",
    "#     if filename.endswith(\".pdf\"):\n",
    "        \n",
    "#         filename_s = filename[:-4]  # Remove '.pdf'\n",
    "#         pdf_path = os.path.join(PDF_DIRECTORY, filename)\n",
    "#         with fitz.open(pdf_path) as doc:\n",
    "#             num_pages = len(doc)\n",
    "#         for i in range(num_pages):\n",
    "            \n",
    "#             file_path_md = os.path.join(md_base, f\"{filename_s}_page_{i+1}.md\")\n",
    "\n",
    "#             md_text = pymupdf4llm.to_markdown(\n",
    "#                 f\"./{PDF_DIRECTORY}/{filename}\",\n",
    "#                 write_images=False,\n",
    "#                 filename=f\"{filename_s}\",\n",
    "#                 pages=[i]\n",
    "#             )\n",
    "#             pathlib.Path(file_path_md).write_bytes(md_text.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ceae223",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_md_text(text):\n",
    "    # Split text into lines\n",
    "    text = re.sub(r\"-[\\u00AD\\u200B\\u200C\\u200D\\u200E\\u200F]*\\s*\\n[\\u00AD\\u200B\\u200C\\u200D\\u200E\\u200F]*\\s*\", \"\", text)\n",
    "    text = re.sub(r\"[\\u00AD\\u200B\\u200C\\u200D\\u200E\\u200F]\\s*\", \"\", text)\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    cleaned_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        # Skip lines that only contain a number (e.g., page numbers)\n",
    "        if re.fullmatch(r'\\s*\\d+\\s*', line):\n",
    "            continue\n",
    "        # Skip empty lines\n",
    "        if not stripped_line:\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    \n",
    "    # Join all lines into one paragraph-like text\n",
    "    # merged_text = ' '.join(cleaned_lines)\n",
    "    # Re-join lines for further processing\n",
    "    merged_text = \"\\n\".join(cleaned_lines)\n",
    "    # Fix hyphenated line breaks: \"infor-\\nmation\" â†’ \"information\"\n",
    "    # merged_text = re.sub(r\"-\\s*\\n\\s*\", \"\", merged_text)\n",
    "    # Normalize whitespace\n",
    "    merged_text = re.sub(r\"\\s+\", \" \", merged_text)\n",
    "    # Clean up space before punctuation\n",
    "    # merged_text = re.sub(r\" +\\.\\s\", \". \", merged_text)\n",
    "    \n",
    "    return CONTROL_SPACE_REGEX.sub('', merged_text).strip()\n",
    "    \n",
    "    return merged_text\n",
    "\n",
    "def get_sentence_end(paragraph):\n",
    "    sentence_end = max(\n",
    "        (m.end() for m in re.finditer(r'(?<=[.!?])\\s', paragraph[:MAX_CHUNK])),\n",
    "        default=None\n",
    "    )\n",
    "    if not sentence_end:\n",
    "        sentence_end = paragraph[:MAX_CHUNK].rfind('\\n')\n",
    "    if sentence_end <= 0:\n",
    "        sentence_end = paragraph[:MAX_CHUNK].rfind(' ')\n",
    "    if sentence_end <= 0:\n",
    "        sentence_end = MAX_CHUNK\n",
    "    return sentence_end\n",
    "\n",
    "def split_large_paragraph(paragraph):\n",
    "    chunks = []\n",
    "    while len(paragraph) > MAX_CHUNK:\n",
    "        sentence_end = get_sentence_end(paragraph)\n",
    "        chunk = paragraph[:sentence_end].strip()\n",
    "        chunks.append(chunk)\n",
    "        paragraph = paragraph[sentence_end:].strip()\n",
    "    if paragraph:\n",
    "        chunks.append(paragraph)\n",
    "    return chunks\n",
    "\n",
    "def is_title_like(paragraph):\n",
    "    words = paragraph.strip().split()\n",
    "    return len(paragraph) < 50 and len(words) <= 6\n",
    "\n",
    "def is_page_number_like(paragraph):\n",
    "    words = paragraph.strip().split()\n",
    "    return len(paragraph) < 5 and len(words) <= 2\n",
    "\n",
    "def split_into_paragraphs(text):\n",
    "    lines = text.splitlines()\n",
    "    paragraphs = []\n",
    "    buffer = []\n",
    "    in_table = False\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        if stripped.startswith(\"|\"):\n",
    "            # Table row\n",
    "            buffer.append(line)\n",
    "            in_table = True\n",
    "        elif in_table and not stripped:\n",
    "            # Blank line ends the table\n",
    "            paragraphs.append(\"\\n\".join(buffer).strip())\n",
    "            buffer = []\n",
    "            in_table = False\n",
    "        elif in_table:\n",
    "            # Still in table\n",
    "            buffer.append(line)\n",
    "        elif not stripped:\n",
    "            # Blank line ends current paragraph\n",
    "            if buffer:\n",
    "                paragraphs.append(\"\\n\".join(buffer).strip())\n",
    "                buffer = []\n",
    "        else:\n",
    "            # Normal paragraph line\n",
    "            buffer.append(line)\n",
    "\n",
    "    # Add any trailing content\n",
    "    if buffer:\n",
    "        paragraphs.append(\"\\n\".join(buffer).strip())\n",
    "\n",
    "    return [p for p in paragraphs if p]\n",
    "\n",
    "def para_split(text):\n",
    "    full_text = []\n",
    "    growing_chunk = \"\"\n",
    "    title_buffer = \"\"\n",
    "    paragraphs = split_into_paragraphs(text)\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        para_len = len(paragraph)\n",
    "\n",
    "        if paragraph.startswith(\"|\"):\n",
    "            # Always flush before and after a table block\n",
    "            if growing_chunk.strip():\n",
    "                full_text.append(growing_chunk.strip())\n",
    "                growing_chunk = \"\"\n",
    "            full_text.append(paragraph)\n",
    "            continue\n",
    "\n",
    "        if is_title_like(paragraph):\n",
    "            title_buffer = paragraph\n",
    "            continue\n",
    "\n",
    "        if title_buffer:\n",
    "            paragraph = title_buffer + \"\\n\\n\" + paragraph\n",
    "            title_buffer = \"\"\n",
    "\n",
    "        if para_len < 50:\n",
    "            growing_chunk += paragraph + \"\\n\\n\"\n",
    "        elif para_len < MIN_CHUNK and len(growing_chunk) + para_len < MAX_CHUNK:\n",
    "            growing_chunk += paragraph + \"\\n\\n\"\n",
    "        else:\n",
    "            if growing_chunk.strip():\n",
    "                full_text.append(growing_chunk.strip())\n",
    "                growing_chunk = \"\"\n",
    "\n",
    "            if para_len > MAX_CHUNK:\n",
    "                full_text.extend(split_large_paragraph(paragraph))\n",
    "            else:\n",
    "                full_text.append(paragraph)\n",
    "\n",
    "    if title_buffer:\n",
    "        growing_chunk += title_buffer + \"\\n\\n\"\n",
    "\n",
    "    if growing_chunk.strip():\n",
    "        full_text.append(growing_chunk.strip())\n",
    "\n",
    "    return full_text\n",
    "\n",
    "def remove_md_stuff(text):\n",
    "    content = re.sub(r'(?:\\n)?#{1,6}|(?:\\n)?```(?:.|\\n)*?```|(?:\\n)?---+|(?:\\n)?___+', '', text)\n",
    "\n",
    "    # Replace spaces with a single space\n",
    "    content = re.sub(r' +', ' ', content)\n",
    "\n",
    "    # Remove bold (handles **bold** and __bold__)\n",
    "    content = re.sub(r'(\\*\\*|__)(.*?)\\1', r'\\2', content)\n",
    "\n",
    "    # Remove italic (handles *italic* and _italic_)\n",
    "    content = re.sub(r'(\\*|_)(.*?)\\1', r'\\2', content)\n",
    "        \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f09263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md_files = list(pathlib.Path(md_base).rglob(\"*.md\"))\n",
    "splitter = MarkdownTextSplitter(chunk_size=512, chunk_overlap=0)\n",
    "\n",
    "for md_file in md_files:\n",
    "    # Read the .md file\n",
    "    with md_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        markdown_text = f.read()\n",
    "\n",
    "    markdown_text = remove_md_stuff(markdown_text)\n",
    "    # Split into chunks\n",
    "    docs = para_split(markdown_text)\n",
    "    # docs = splitter.split_text(remove_md_stuff(markdown_text))\n",
    "\n",
    "    # Get the relative path from md_base\n",
    "    relative_path = md_file.relative_to(md_base)\n",
    "\n",
    "    # Build the new path under txt_base with .txt extension\n",
    "    txt_file_path = txt_base / relative_path.with_suffix(\".txt\")\n",
    "\n",
    "    # Ensure the parent directory exists\n",
    "    txt_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Write chunks to the new .txt file\n",
    "    with txt_file_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for i, chunk in enumerate(docs):\n",
    "            chunk = clean_md_text(chunk)\n",
    "            if not is_page_number_like(chunk):\n",
    "                f.write(f\"Chunk: {i+1}\\n{chunk}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
