{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "39ccff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz\n",
    "import tomli\n",
    "\n",
    "\n",
    "TOML_DIRECTORY = \"../../questions/cleaned/\"\n",
    "PDF_DIRECTORY = \"../../pdf_data\"\n",
    "TXT_DIRECTORY = \"../../txt_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117f5b4",
   "metadata": {},
   "source": [
    "First get all pdfs as text files. Might give some format error but its ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9330eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: No default Layer config\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(input_text):\n",
    "    text = input_text.strip()\n",
    "    # Remove invisible/zero-width Unicode characters\n",
    "    text = re.sub(r\"[\\u00AD\\u200B\\u200C\\u200D\\u200E\\u200F]\\s*\", \"\", text)\n",
    "    # Split into lines to check for page numbers\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    if lines and re.fullmatch(r\"\\s*\\d{1,3}\\s*\", lines[0]):\n",
    "        lines = lines[1:]\n",
    "    if lines and re.fullmatch(r\"\\s*\\d{1,3}\\s*\", lines[-1]):\n",
    "        lines = lines[:-1]\n",
    "        \n",
    "    # Re-join lines for further processing\n",
    "    text = \"\\n\".join(lines)\n",
    "    # Fix hyphenated line breaks: \"infor-\\nmation\" → \"information\"\n",
    "    text = re.sub(r\"-\\s*\\n\\s*\", \"\", text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # Clean up space before punctuation\n",
    "    text = re.sub(r\" +\\.\\s\", \". \", text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def chunk_pdf_by_tokens(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    text_and_pagenumber = []  # List [(page_number, page_text)]\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(sort=True)\n",
    "        if text.strip():  # Skip empty pages\n",
    "            norm_text = normalize_text(text)\n",
    "            text_and_pagenumber.append((i + 1, norm_text + \" \"))\n",
    "    doc.close()\n",
    "    return text_and_pagenumber\n",
    "\n",
    "for filename in os.listdir(PDF_DIRECTORY):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        filename_s = filename[:-4]  # Remove '.pdf'\n",
    "        pdf_path = os.path.join(PDF_DIRECTORY, filename)\n",
    "        chunks = chunk_pdf_by_tokens(pdf_path)\n",
    "\n",
    "        os.makedirs(TXT_DIRECTORY, exist_ok=True)\n",
    "        file_path_txt = os.path.join(TXT_DIRECTORY, f\"{filename_s}.txt\")\n",
    "\n",
    "        with open(file_path_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "            for chunk in chunks:\n",
    "                f.write(chunk[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c6766",
   "metadata": {},
   "source": [
    "Then load toml files to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b78fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(toml_dir):\n",
    "    all_embedded_questions = {}\n",
    "    for filename in os.listdir(toml_dir):\n",
    "        if filename.endswith(\".toml\"):\n",
    "            file_path = os.path.join(toml_dir, filename)\n",
    "            with open(file_path, \"rb\") as f:  # tomli requires binary mode\n",
    "                toml_data = tomli.load(f)\n",
    "            questions = toml_data.get(\"questions\", [])\n",
    "            for question in questions:\n",
    "                q_id = question.get(\"id\")\n",
    "                if q_id:\n",
    "                    all_embedded_questions[q_id] = question\n",
    "    return all_embedded_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba4c24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_dict = get_questions(TOML_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665e446",
   "metadata": {},
   "source": [
    "Now check if answer is found in text files. This is basically a bad word match. But it's a starting point.\n",
    "\n",
    "Also checks if the answer was found in the right file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6058d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer for question DC018 not found.\n",
      "Check Filename: 'AgriFood_WP20112.pdf'\n",
      "or Answer: 'Små butiker förlorar intäkter om butiken befinner sig inom en radie om 1,5 till 9 kilometer från en stor butik, men förlusten är bara knappt en tredjedel jämfört med om butikerna hade varit belägna högst 1,5 kilometer från varandra.'.\n",
      "\n",
      "Answer for question DC038 not found.\n",
      "Check Filename: 'Examensarbete150510.pdf'\n",
      "or Answer: 'Sammanfattningsvis har reformarbetet haft ett par huvudsakliga syften, nämligen att införa ett konsekvent konsumentskydd också inom personförsäkringarnas område, att anpassa lagreglerna till nya försäkringsformer, en allmän modernisering av lagstiftningen och att ge ett förstärkt skydd för försäkringstagaren som ett näst intill nödvändigt komplement till avregleringen av försäkringsverksamheten.'.\n",
      "\n",
      "Answer for question DC076 not found.\n",
      "Check Filename: 'Lucas_RohrHansen_VT22.pdf'\n",
      "or Answer: 'Gränsdragningsproblematiken ligger i att utreda om det är en förvärvsverksamhet som bedrivs yrkesmässigt och självständigt enligt 13 kap. 1 § IL, eller om verksamheten förvisso bedrivs självständigt men brister vad gäller yrkesmässighet och/eller vinstsyfte, se 12 kap. 37 § IL.'.\n",
      "\n",
      "Answer for question DC104 not found.\n",
      "Check Filename: 'tmptmprfscxr.pdf'\n",
      "or Answer: 'Ur teknisk synvinkel brukar framhållas att något som särskiljer försäkring från andra, liknande företeelser, är att försäkringstagarens prestation - försäkringspremien - grundar sig på en beräkning av risken för skada som utförts med försäkringstekniska metoder.'.\n",
      "\n",
      "Answer for question DC148 not found.\n",
      "Check Filename: 'ADHD-DIAGNOS_I_VARUKORGEN.pdf'\n",
      "or Answer: 'Med erbjudandet om ADHD-utredningar följer även att företagen behöver redogöra för ADHD- diagnosens orsaker och symptom.'.\n",
      "\n",
      "Answer for question DC194 not found.\n",
      "Check Filename: 'Faktablad-om-arbetsmilijorisker-under-graviditet.pdf'\n",
      "or Answer: 'Exponering för oorganiskt bly kan leda till minskat spermieantal och ökat antal onormala spermier vid blodblynivåer omkring 2-2,5 μmol/L.'.\n"
     ]
    }
   ],
   "source": [
    "def check_answers_in_txt(question_dict, txt_directory):\n",
    "    for question_id, question in question_dict.items():\n",
    "        answer = question['answer']\n",
    "        filename_toml = question['files'][0]['file']\n",
    "\n",
    "        # Build full path to the expected .txt file\n",
    "        expected_txt_file = os.path.splitext(filename_toml)[0] + '.txt'\n",
    "        expected_txt_path = os.path.join(txt_directory, expected_txt_file)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(expected_txt_path):\n",
    "            with open(expected_txt_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                if answer in content:\n",
    "                    continue  # Answer found in correct file\n",
    "                else:\n",
    "                    print(f\"\\nAnswer for question {question_id} not found.\\nCheck Filename: '{expected_txt_file[0:-4]}.pdf'\\nor Answer: '{answer}'.\")\n",
    "        else:\n",
    "            print(f\"Expected file '{expected_txt_file[0:-4]}.pdf' for question {question_id} does not exist in the pdf directory.\")\n",
    "\n",
    "question_dict = get_questions(TOML_DIRECTORY)\n",
    "check_answers_in_txt(question_dict, TXT_DIRECTORY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
