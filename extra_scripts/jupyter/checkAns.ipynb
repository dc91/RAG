{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ccff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz\n",
    "import tomli\n",
    "\n",
    "\n",
    "TOML_DIRECTORY = \"../../questions/raw/\"\n",
    "PDF_DIRECTORY = \"../../pdf_data\"\n",
    "TXT_DIRECTORY = \"../../txt_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117f5b4",
   "metadata": {},
   "source": [
    "First get all pdfs as text files. Might give some format error but its ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9330eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: No default Layer config\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(input_text):\n",
    "    text = input_text.strip()\n",
    "    # Remove invisible/zero-width Unicode characters\n",
    "    text = re.sub(r\"[\\u00AD\\u200B\\u200C\\u200D\\u200E\\u200F]\\s*\", \"\", text)\n",
    "    # Split into lines to check for page numbers\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    if lines and re.fullmatch(r\"\\s*\\d{1,3}\\s*\", lines[0]):\n",
    "        lines = lines[1:]\n",
    "    if lines and re.fullmatch(r\"\\s*\\d{1,3}\\s*\", lines[-1]):\n",
    "        lines = lines[:-1]\n",
    "        \n",
    "    # Re-join lines for further processing\n",
    "    text = \"\\n\".join(lines)\n",
    "    # Fix hyphenated line breaks: \"infor-\\nmation\" → \"information\"\n",
    "    text = re.sub(r\"-\\s*\\n\\s*\", \"\", text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # Clean up space before punctuation\n",
    "    text = re.sub(r\" +\\.\\s\", \". \", text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def chunk_pdf_by_tokens(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    text_and_pagenumber = []  # List [(page_number, page_text)]\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(sort=True)\n",
    "        if text.strip():  # Skip empty pages\n",
    "            norm_text = normalize_text(text)\n",
    "            text_and_pagenumber.append((i + 1, norm_text + \" \"))\n",
    "    doc.close()\n",
    "    return text_and_pagenumber\n",
    "\n",
    "for filename in os.listdir(PDF_DIRECTORY):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        filename_s = filename[:-4]  # Remove '.pdf'\n",
    "        pdf_path = os.path.join(PDF_DIRECTORY, filename)\n",
    "        chunks = chunk_pdf_by_tokens(pdf_path)\n",
    "\n",
    "        os.makedirs(TXT_DIRECTORY, exist_ok=True)\n",
    "        file_path_txt = os.path.join(TXT_DIRECTORY, f\"{filename_s}.txt\")\n",
    "\n",
    "        with open(file_path_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "            for chunk in chunks:\n",
    "                f.write(chunk[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c6766",
   "metadata": {},
   "source": [
    "Then load toml files to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b78fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(toml_dir):\n",
    "    all_embedded_questions = {}\n",
    "    for filename in os.listdir(toml_dir):\n",
    "        if filename.endswith(\".toml\"):\n",
    "            file_path = os.path.join(toml_dir, filename)\n",
    "            with open(file_path, \"rb\") as f:  # tomli requires binary mode\n",
    "                toml_data = tomli.load(f)\n",
    "            questions = toml_data.get(\"questions\", [])\n",
    "            for question in questions:\n",
    "                q_id = question.get(\"id\")\n",
    "                if q_id:\n",
    "                    all_embedded_questions[q_id] = question\n",
    "    return all_embedded_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba4c24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question_dict = get_questions(TOML_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665e446",
   "metadata": {},
   "source": [
    "Now check if answer is found in text files. This is basically a bad word match. But it's a starting point.\n",
    "\n",
    "Also checks if the answer was found in the right file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6058d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer for question RN065 not found.\n",
      "Check Filename: 'bygga_bedoma_betygsatta_bättre_elevernas_kunskap.pdf'\n",
      "or Answer: 'ett sätt att öka reliabiliteten är att utöka mängden frågor i ett prov och på så sätt ge elever fler och olika möjligheter att visa att de förstår ett moment'.\n",
      "Note: This answer is spread across multiple pages [292, 293], so that could cause a miss in detection. But still check it!\n",
      "\n",
      "Answer for question RN116 not found.\n",
      "Check Filename: 'På samma klot.pdf'\n",
      "or Answer: 'francis bacon (1561–1626) menade denna att vetenskap skulle bygga på kunskaper inhämtade genom experiment och från praktiker,'.\n"
     ]
    }
   ],
   "source": [
    "def check_answers_in_txt(question_dict, txt_directory):\n",
    "    for question_id, question in question_dict.items():\n",
    "        answer = question['answer'].lower()\n",
    "        filename_toml = question['files'][0]['file']\n",
    "        multiple_pages = True if len(question['files'][0]['page_numbers']) > 1 else False\n",
    "        hyphenated_ans = True if \"-\" in answer else False\n",
    "\n",
    "        # Build full path to the expected .txt file\n",
    "        expected_txt_file = os.path.splitext(filename_toml)[0] + '.txt'\n",
    "        expected_txt_path = os.path.join(txt_directory, expected_txt_file)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(expected_txt_path):\n",
    "            with open(expected_txt_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().lower()\n",
    "                if answer in content:\n",
    "                    continue  # Answer found in correct file\n",
    "                else:\n",
    "                    print(f\"\\nAnswer for question {question_id} not found.\\nCheck Filename: '{expected_txt_file[0:-4]}.pdf'\\nor Answer: '{answer}'.\")\n",
    "                    if multiple_pages:\n",
    "                        print(f\"Note: This answer is spread across multiple pages {question['files'][0]['page_numbers']}, so that could cause a miss in detection. But still check it!\")\n",
    "                    if hyphenated_ans:\n",
    "                        print(\"Note: This answer contains a hyphen '-', which might affect detection. Please check manually!\")\n",
    "        else:\n",
    "            print(f\"Expected file '{expected_txt_file[0:-4]}.pdf' for question {question_id} does not exist in the pdf directory.\")\n",
    "\n",
    "question_dict = get_questions(TOML_DIRECTORY)\n",
    "check_answers_in_txt(question_dict, TXT_DIRECTORY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
